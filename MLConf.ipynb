{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TweetGroups\n",
    "\n",
    "Twitter is an integral part of marketing and can’t be ignored.  Twitter interactions can not only be a good metric for tracking a marketing campaign’s performance, but it can also be the cause of product or brands success and failure.\n",
    "\n",
    "In recent years we have all seen examples of bad tweets that have ruined reputations and tarnished brands, so making sure that your company's tweets are throughly planned is essential.  The process of creating and maintaining an effective presence on Twitter is a complex one, but TweetGroups can help you get started:\n",
    "\n",
    "#### TweetGroups helps to answer two fundamental marketing questions:\n",
    "1.  What are our market segements (groups of customers)?\n",
    "2.  How do we engage these customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is Dimensionality Reduction Important?\n",
    "\n",
    "The text written on social media can be random, arbitrary, and have a wide variety of tokens (including words/phrases/emojis).  Without a way to reduce these high-dimensional token matricies, you can run in to performance issues and clustering may be difficult.  This is particularly import in our case, where we are using clustering algorthims that do not need a n_topics paraments (ie. Affinity Progpogation, DBSCAN, Mean Shift, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-processing with spaCy\n",
    "\n",
    "For text processing step we chose to use the Natural Language Processing library spaCy due to a few advantages over other libraries:\n",
    "\n",
    "1.  Performance: spaCy is written in Cython and contains a wide array of NLP functions that can be parallelized and execute quickly\n",
    "\n",
    "2.  Flexability: spaCy has functions that are particularly useful for social media data, including the ability to tokenize emojis, parts of speech tagging, and named entity recognition\n",
    "\n",
    "3.  Usability: spaCy code is clear, concise, well-documented and actively supported\n",
    "\n",
    "Let's show a quick performance comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import spacy\n",
    "import timeit\n",
    "import textacy\n",
    "%timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.34 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100 loops, best of 3: 6.3 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Loading a pickled list of tweets\n",
    "import pandas as pd\n",
    "tweet_list = pd.read_pickle('tweet_list_gopro.pkl')\n",
    "# this list contains about 14000 tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Textacy is tokenization package built on top of spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 12.1 s per loop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TextCorpus(2510 docs; 232695 tokens)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit corpus = textacy.TextCorpus.from_texts('en',tweet_list)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_textblob(docs):\n",
    "    tweetblob = []\n",
    "    for doc in docs:\n",
    "        tweetblob.append(textblob.TextBlob(doc))\n",
    "    return tweetblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 112 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit tokenize_textblob(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here I can walkthrough the process using sklearn tools\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
